{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256\n",
    "NUM_SAMPLES = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where we will store the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "target_texts_inputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples:  799\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for line in open('./kor.txt', encoding='utf-8'):\n",
    "    t += 1\n",
    "    \n",
    "    # keeping limited number of samples because of saving time.\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "    \n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    \n",
    "    # each sequence needs to be the same length.\n",
    "    input_text, translation = line.rstrip().split('\\t')\n",
    "    target_text = translation + ' <eos>'\n",
    "    target_text_input = '<sos> ' + translation\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "    \n",
    "print(\"num samples: \", len(input_texts))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('No way!', '절대 아니야. <eos>', '<sos> 절대 아니야.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[2], target_texts[2], target_texts_inputs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the inputs - english\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "\n",
    "# transform\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1062 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "# {word: sequence}\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print(\"Found %s unique input tokens.\" % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_length\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "max_len_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the outputs - korean\n",
    "\n",
    "# don't fitler out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequncess_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1826 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print(\"Found %s unique output tokens.\" % len(word2idx_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- index가 0부터가 아니라 1부터 주어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store number of output words for later\n",
    "# remeber to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape:  (799, 19)\n",
      "encoder_data[0]:  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 79]\n",
      "decoder_data[0]:  [  2 438   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "decoder_Data.shape:  (799, 16)\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape: \", encoder_inputs.shape)\n",
    "print(\"encoder_data[0]: \", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequncess_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_data[0]: \", decoder_inputs[0])\n",
    "print(\"decoder_Data.shape: \", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('./glove.6B.%sd.txt' % EMBEDDING_DIM), encoding='utf-8') as f:\n",
    "    # is just a space-separated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  # trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_state=True, # we only need last lstm output state\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    ")\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "# encoder_outputs, h = encoder(x) #gru\n",
    "\n",
    "# keep only the states to pass into decoder\n",
    "encoder_states = [h, c]\n",
    "# encoder_states = [state_h] # gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using [h, c] as initial state.\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "decoder_embedding = Embedding(num_words_output, LATENT_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "# since the decoder is a \"to-many\" model we want to have\n",
    "# return_sequences=True\n",
    "decoder_lstm = LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  return_state=True,\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    ")\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "  decoder_inputs_x,\n",
    "  initial_state=encoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dense layer for predictions\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 19)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 19, 100)      106300      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 16, 256)      467712      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 365568      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 16, 256), (N 525312      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16, 1827)     469539      lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,934,431\n",
      "Trainable params: 1,934,431\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model object\n",
    "# teacher forcing\n",
    "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 639 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 3.7174 - acc: 0.6503 - val_loss: 3.4322 - val_acc: 0.5574\n",
      "Epoch 2/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.7978 - acc: 0.7317 - val_loss: 3.3090 - val_acc: 0.5719\n",
      "Epoch 3/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.7519 - acc: 0.7361 - val_loss: 3.5171 - val_acc: 0.5684\n",
      "Epoch 4/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.6772 - acc: 0.7495 - val_loss: 3.6531 - val_acc: 0.5703\n",
      "Epoch 5/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.6190 - acc: 0.7613 - val_loss: 3.5496 - val_acc: 0.5777\n",
      "Epoch 6/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.5705 - acc: 0.7720 - val_loss: 3.5337 - val_acc: 0.6047\n",
      "Epoch 7/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.5179 - acc: 0.7881 - val_loss: 3.7472 - val_acc: 0.5840\n",
      "Epoch 8/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.4889 - acc: 0.7883 - val_loss: 3.7477 - val_acc: 0.5980\n",
      "Epoch 9/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.4613 - acc: 0.7896 - val_loss: 3.7778 - val_acc: 0.6133\n",
      "Epoch 10/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.4302 - acc: 0.7913 - val_loss: 3.8484 - val_acc: 0.6145\n",
      "Epoch 11/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.3949 - acc: 0.7922 - val_loss: 3.8737 - val_acc: 0.6176\n",
      "Epoch 12/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.3621 - acc: 0.7924 - val_loss: 3.9830 - val_acc: 0.6207\n",
      "Epoch 13/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.3244 - acc: 0.7939 - val_loss: 4.0368 - val_acc: 0.6281\n",
      "Epoch 14/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.2830 - acc: 0.7961 - val_loss: 4.0362 - val_acc: 0.6312\n",
      "Epoch 15/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.2545 - acc: 0.7975 - val_loss: 4.0711 - val_acc: 0.6312\n",
      "Epoch 16/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.2214 - acc: 0.7991 - val_loss: 4.2056 - val_acc: 0.6352\n",
      "Epoch 17/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.1760 - acc: 0.8012 - val_loss: 4.0866 - val_acc: 0.6344\n",
      "Epoch 18/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.1426 - acc: 0.8032 - val_loss: 4.1860 - val_acc: 0.6336\n",
      "Epoch 19/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.1081 - acc: 0.8053 - val_loss: 4.3239 - val_acc: 0.6348\n",
      "Epoch 20/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.0680 - acc: 0.8079 - val_loss: 4.3183 - val_acc: 0.6336\n",
      "Epoch 21/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 1.0392 - acc: 0.8109 - val_loss: 4.3551 - val_acc: 0.6367\n",
      "Epoch 22/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.9938 - acc: 0.8130 - val_loss: 4.3737 - val_acc: 0.6367\n",
      "Epoch 23/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.9576 - acc: 0.8165 - val_loss: 4.4634 - val_acc: 0.6352\n",
      "Epoch 24/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.9254 - acc: 0.8196 - val_loss: 4.3977 - val_acc: 0.6352\n",
      "Epoch 25/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.8811 - acc: 0.8224 - val_loss: 4.4467 - val_acc: 0.6355\n",
      "Epoch 26/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.8493 - acc: 0.8265 - val_loss: 4.5367 - val_acc: 0.6352\n",
      "Epoch 27/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.8069 - acc: 0.8347 - val_loss: 4.4413 - val_acc: 0.6367\n",
      "Epoch 28/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.7742 - acc: 0.8411 - val_loss: 4.4986 - val_acc: 0.6383\n",
      "Epoch 29/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.7318 - acc: 0.8483 - val_loss: 4.5773 - val_acc: 0.6371\n",
      "Epoch 30/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.6956 - acc: 0.8569 - val_loss: 4.4986 - val_acc: 0.6379\n",
      "Epoch 31/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.6541 - acc: 0.8674 - val_loss: 4.5597 - val_acc: 0.6375\n",
      "Epoch 32/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.6211 - acc: 0.8772 - val_loss: 4.4947 - val_acc: 0.6367\n",
      "Epoch 33/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.5869 - acc: 0.8905 - val_loss: 4.5346 - val_acc: 0.6375\n",
      "Epoch 34/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.5481 - acc: 0.9051 - val_loss: 4.5863 - val_acc: 0.6383\n",
      "Epoch 35/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.5145 - acc: 0.9113 - val_loss: 4.5908 - val_acc: 0.6379\n",
      "Epoch 36/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.4821 - acc: 0.9207 - val_loss: 4.5815 - val_acc: 0.6367\n",
      "Epoch 37/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.4463 - acc: 0.9295 - val_loss: 4.5937 - val_acc: 0.6371\n",
      "Epoch 38/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.4120 - acc: 0.9368 - val_loss: 4.5658 - val_acc: 0.6332\n",
      "Epoch 39/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.3877 - acc: 0.9445 - val_loss: 4.5502 - val_acc: 0.6328\n",
      "Epoch 40/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.3568 - acc: 0.9487 - val_loss: 4.5811 - val_acc: 0.6344\n",
      "Epoch 41/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.3348 - acc: 0.9539 - val_loss: 4.5507 - val_acc: 0.6309\n",
      "Epoch 42/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.3018 - acc: 0.9595 - val_loss: 4.6043 - val_acc: 0.6312\n",
      "Epoch 43/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.2802 - acc: 0.9640 - val_loss: 4.5998 - val_acc: 0.6285\n",
      "Epoch 44/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.2554 - acc: 0.9689 - val_loss: 4.6217 - val_acc: 0.6301\n",
      "Epoch 45/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.2361 - acc: 0.9687 - val_loss: 4.6085 - val_acc: 0.6281\n",
      "Epoch 46/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.2118 - acc: 0.9723 - val_loss: 4.6356 - val_acc: 0.6258\n",
      "Epoch 47/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.1994 - acc: 0.9748 - val_loss: 4.6307 - val_acc: 0.6242\n",
      "Epoch 48/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.1770 - acc: 0.9771 - val_loss: 4.6209 - val_acc: 0.6281\n",
      "Epoch 49/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.1641 - acc: 0.9784 - val_loss: 4.6276 - val_acc: 0.6270\n",
      "Epoch 50/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.1493 - acc: 0.9797 - val_loss: 4.6271 - val_acc: 0.6258\n",
      "Epoch 51/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.1353 - acc: 0.9815 - val_loss: 4.6260 - val_acc: 0.6238\n",
      "Epoch 52/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.1248 - acc: 0.9818 - val_loss: 4.6579 - val_acc: 0.6219\n",
      "Epoch 53/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.1115 - acc: 0.9823 - val_loss: 4.6541 - val_acc: 0.6230\n",
      "Epoch 54/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.1038 - acc: 0.9832 - val_loss: 4.6367 - val_acc: 0.6238\n",
      "Epoch 55/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0960 - acc: 0.9844 - val_loss: 4.6706 - val_acc: 0.6246\n",
      "Epoch 56/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0867 - acc: 0.9854 - val_loss: 4.6764 - val_acc: 0.6223\n",
      "Epoch 57/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0777 - acc: 0.9861 - val_loss: 4.6913 - val_acc: 0.6223\n",
      "Epoch 58/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0714 - acc: 0.9862 - val_loss: 4.6827 - val_acc: 0.6199\n",
      "Epoch 59/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0683 - acc: 0.9863 - val_loss: 4.6975 - val_acc: 0.6227\n",
      "Epoch 60/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0611 - acc: 0.9877 - val_loss: 4.7062 - val_acc: 0.6191\n",
      "Epoch 61/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0580 - acc: 0.9857 - val_loss: 4.7196 - val_acc: 0.6219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0524 - acc: 0.9866 - val_loss: 4.7234 - val_acc: 0.6203\n",
      "Epoch 63/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0498 - acc: 0.9869 - val_loss: 4.7438 - val_acc: 0.6141\n",
      "Epoch 64/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0462 - acc: 0.9867 - val_loss: 4.7397 - val_acc: 0.6141\n",
      "Epoch 65/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0434 - acc: 0.9877 - val_loss: 4.7272 - val_acc: 0.6176\n",
      "Epoch 66/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0410 - acc: 0.9868 - val_loss: 4.7466 - val_acc: 0.6191\n",
      "Epoch 67/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0386 - acc: 0.9877 - val_loss: 4.7491 - val_acc: 0.6172\n",
      "Epoch 68/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0363 - acc: 0.9868 - val_loss: 4.7669 - val_acc: 0.6168\n",
      "Epoch 69/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0346 - acc: 0.9876 - val_loss: 4.7726 - val_acc: 0.6133\n",
      "Epoch 70/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0330 - acc: 0.9873 - val_loss: 4.7775 - val_acc: 0.6160\n",
      "Epoch 71/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0315 - acc: 0.9877 - val_loss: 4.7709 - val_acc: 0.6137\n",
      "Epoch 72/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0304 - acc: 0.9875 - val_loss: 4.8013 - val_acc: 0.6141\n",
      "Epoch 73/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0291 - acc: 0.9875 - val_loss: 4.7907 - val_acc: 0.6137\n",
      "Epoch 74/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0278 - acc: 0.9889 - val_loss: 4.8137 - val_acc: 0.6164\n",
      "Epoch 75/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0276 - acc: 0.9875 - val_loss: 4.8135 - val_acc: 0.6152\n",
      "Epoch 76/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0258 - acc: 0.9881 - val_loss: 4.8320 - val_acc: 0.6129\n",
      "Epoch 77/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0250 - acc: 0.9879 - val_loss: 4.8388 - val_acc: 0.6168\n",
      "Epoch 78/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0243 - acc: 0.9889 - val_loss: 4.8420 - val_acc: 0.6148\n",
      "Epoch 79/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0242 - acc: 0.9873 - val_loss: 4.8584 - val_acc: 0.6117\n",
      "Epoch 80/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0226 - acc: 0.9888 - val_loss: 4.8496 - val_acc: 0.6137\n",
      "Epoch 81/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0227 - acc: 0.9877 - val_loss: 4.8614 - val_acc: 0.6105\n",
      "Epoch 82/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0218 - acc: 0.9888 - val_loss: 4.8518 - val_acc: 0.6137\n",
      "Epoch 83/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0216 - acc: 0.9893 - val_loss: 4.8750 - val_acc: 0.6117\n",
      "Epoch 84/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0206 - acc: 0.9895 - val_loss: 4.8665 - val_acc: 0.6133\n",
      "Epoch 85/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0203 - acc: 0.9888 - val_loss: 4.8664 - val_acc: 0.6121\n",
      "Epoch 86/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0207 - acc: 0.9891 - val_loss: 4.8917 - val_acc: 0.6117\n",
      "Epoch 87/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0198 - acc: 0.9882 - val_loss: 4.9016 - val_acc: 0.6098\n",
      "Epoch 88/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0194 - acc: 0.9889 - val_loss: 4.8983 - val_acc: 0.6125\n",
      "Epoch 89/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0190 - acc: 0.9890 - val_loss: 4.9130 - val_acc: 0.6121\n",
      "Epoch 90/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0187 - acc: 0.9883 - val_loss: 4.9353 - val_acc: 0.6086\n",
      "Epoch 91/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0188 - acc: 0.9881 - val_loss: 4.9163 - val_acc: 0.6117\n",
      "Epoch 92/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0184 - acc: 0.9892 - val_loss: 4.9289 - val_acc: 0.6105\n",
      "Epoch 93/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0183 - acc: 0.9888 - val_loss: 4.9285 - val_acc: 0.6121\n",
      "Epoch 94/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0182 - acc: 0.9884 - val_loss: 4.9369 - val_acc: 0.6078\n",
      "Epoch 95/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0179 - acc: 0.9881 - val_loss: 4.9459 - val_acc: 0.6094\n",
      "Epoch 96/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0177 - acc: 0.9889 - val_loss: 4.9531 - val_acc: 0.6121\n",
      "Epoch 97/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0177 - acc: 0.9890 - val_loss: 4.9550 - val_acc: 0.6098\n",
      "Epoch 98/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0172 - acc: 0.9893 - val_loss: 4.9557 - val_acc: 0.6098\n",
      "Epoch 99/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0170 - acc: 0.9888 - val_loss: 4.9742 - val_acc: 0.6090\n",
      "Epoch 100/100\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0170 - acc: 0.9890 - val_loss: 4.9794 - val_acc: 0.6082\n"
     ]
    }
   ],
   "source": [
    "# Compile the model and train it\n",
    "model.compile(\n",
    "  optimizer='rmsprop',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 16, 1827)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIm2MgltEpI1RcIuItDH/D7mX+QwXcKA3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb306f3b630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCincRUSi0P8HIKVMJQgAyXwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb306f373c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py:2344: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# this time, we want to keep the states too, to be output\n",
    "# by our sampling model\n",
    "# 출력이 한개다.\n",
    "decoder_outputs, h, c = decoder_lstm(\n",
    "  decoder_inputs_single_x,\n",
    "  initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "decoder_states = [h, c]\n",
    "# decoder_states = [h] # gru\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# The sampling model\n",
    "# inputs: y(t-1), h(t-1), c(t-1)\n",
    "# outputs: y(t), h(t), c(t)\n",
    "decoder_model = Model(\n",
    "  [decoder_inputs_single] + decoder_states_inputs, \n",
    "  [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 19)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 19, 100)           106300    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 256), (None, 256) 365568    \n",
      "=================================================================\n",
      "Total params: 471,868\n",
      "Trainable params: 471,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         multiple             467712      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   multiple             525312      embedding_2[1][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 multiple             469539      lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,462,563\n",
      "Trainable params: 1,462,563\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    # NOTE: tokenizer lower-cases all words\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # if we get this we break\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    # Create the translation\n",
    "    output_sentence = []\n",
    "    \n",
    "    for _ in range(max_len_target):\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "          [target_seq] + states_value\n",
    "        )\n",
    "        # output_tokens, h = decoder_model.predict(\n",
    "        #     [target_seq] + states_value\n",
    "        # ) # gru\n",
    "\n",
    "        # Get next word\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # End sentence of EOS\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "    \n",
    "        if idx > 0:\n",
    "            word = idx2word_trans[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Update the decoder input\n",
    "        # which is just the word just generated\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        # states_value = [h] # gru\n",
    "\n",
    "    return ' '.join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: After driving for eight hours, Tom just couldn't drive any longer.\n",
      "Translation: 그는 두 시간 동안 더 걸었다.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Do you want to take a walk?\n",
      "Translation: 산책하고 싶어?\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: They're amateurs.\n",
      "Translation: 걔네 초짜야.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: This house is not for sale.\n",
      "Translation: 이 집은 팔려고 내놓은 집 아니에요.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Remember that we're all in the same boat.\n",
      "Translation: 우리는 다 같은 처지에 있지 않는다.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: I don't buy it.\n",
      "Translation: 못 믿어.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Don't pry into my private life.\n",
      "Translation: 내 사생활 캐묻지 마.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: We can't give up.\n",
      "Translation: 포기할 수 없어요.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Let's meet in front of the theater.\n",
      "Translation: 극장 앞에서 만납시다.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: You need to accept your role.\n",
      "Translation: 넌 너의 역할을 받아들일 필요가 있어.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Keep Tom there.\n",
      "Translation: 톰은 여기에 두세요.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Drive carefully.\n",
      "Translation: 운전 조심해.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: You look tired, so you should go to bed early.\n",
      "Translation: 내가 자주 와?\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: I'm heartbroken.\n",
      "Translation: 제 마음이 아파요.\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input: Do you like cooking?\n",
      "Translation: 요리 좋아해요?\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Do some test translations\n",
    "    i = np.random.choice(len(input_texts))\n",
    "    input_seq = encoder_inputs[i:i+1]\n",
    "    translation = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input:', input_texts[i])\n",
    "    print('Translation:', translation)\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith('n'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
